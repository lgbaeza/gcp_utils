{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937a9751-4aa7-43e9-9e1b-b755d45c1d51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Large CDR synthetic record generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e991d1c-92e9-47f7-920e-b9de0435f2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Create the first data: 1000M ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f406035a-79ed-44b2-9fe9-e007415f844c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "project_id = \"\"\n",
    "dataset_id = f\"telco\"\n",
    "table_id = \"cdr\"\n",
    "num_rows_batch = 100 #1M\n",
    "num_cycles = 1\n",
    "cpu_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fca28b7-7c27-47e6-a2e1-5a9da5ddddc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_wom_cdr_data(num_records):\n",
    "    # Define possible values for CDR fields\n",
    "    call_results = [\"Answered\", \"Busy\", \"No Answer\", \"Failed\"]\n",
    "    chilean_area_codes = [\"2\", \"32\", \"33\", \"34\", \"35\", \"41\", \"42\", \"43\", \"45\", \"51\", \"52\", \"53\", \"55\", \"57\", \"58\", \"61\", \"63\", \"64\", \"65\", \"67\", \"71\", \"72\", \"73\", \"75\"] \n",
    "    mobile_prefixes = [\"9\"]  # Chilean mobile numbers typically start with 9\n",
    "\n",
    "    # Generate CDR records\n",
    "    records = []\n",
    "    for i in range(num_records):\n",
    "        start_time = datetime.datetime.now() - datetime.timedelta(days=random.randint(0, 365), \n",
    "                                                                 hours=random.randint(0, 23), \n",
    "                                                                 minutes=random.randint(0, 59),\n",
    "                                                                 seconds=random.randint(0, 1))\n",
    "        call_duration = random.randint(10, 3000)  # Duration in seconds\n",
    "        end_time = start_time + datetime.timedelta(seconds=call_duration)\n",
    "\n",
    "        record = {\n",
    "            \"CALLING_COMPANY\": \"WOM\",\n",
    "            \"CALLING_NUM\": f\"+56{random.choice(mobile_prefixes)}{random.randint(10000000, 99999999)}\",  # WOM mobile\n",
    "            \"CALLED_COMPANY\": random.choice([\"Entel\", \"Movistar\", \"Claro\", \"WOM\"]),  # Other Chilean telcos\n",
    "            \"CALLED_NUMBER\": f\"+56{random.choice([random.choice(chilean_area_codes), random.choice(mobile_prefixes)])}{random.randint(1000000, 99999999)}\",\n",
    "            \"START_TIME\": start_time,\n",
    "            \"END_TIME\": end_time,\n",
    "            \"CHARGE\": round(random.uniform(0.05, 2.50), 2),  # Sample charges\n",
    "            \"CALL_RESULT\": random.choice(call_results)\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a23ec41-792b-406a-90df-87d06d3d6e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def insert_into_bigquery(project_id, dataset_id, table_id, df):\n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    # Get the table reference\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Configure the job\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        # Autodetect the schema from the DataFrame\n",
    "        autodetect=True,\n",
    "        # Specify the write disposition (append to existing table, replace, etc.)\n",
    "        write_disposition=\"WRITE_APPEND\",  # Or WRITE_TRUNCATE, WRITE_EMPTY\n",
    "        # Source format is CSV (you can change this if needed)\n",
    "        source_format=bigquery.SourceFormat.CSV\n",
    "    )\n",
    "\n",
    "    # Load the data into BigQuery\n",
    "    job = client.load_table_from_dataframe(\n",
    "        df, table_ref, job_config=job_config\n",
    "    )\n",
    "\n",
    "    job.result()\n",
    "\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf97454-e1ba-451d-b46f-2250098c160e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_insert_cdr(i):\n",
    "    wom_cdr_data = generate_wom_cdr_data(num_rows_batch)\n",
    "    print(f\"Generated {len(wom_cdr_data)} synthetic rows\")\n",
    "    count_results = insert_into_bigquery(project_id, dataset_id, table_id, wom_cdr_data)\n",
    "    print(f\"******* Round {i}/{num_cycles}: Loaded {count_results} rows into {project_id}.{dataset_id}.{table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d002ac8-598a-4ac8-b2e3-7bb4520b3c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Running using 4 threads for 4 cpus\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cpus = multiprocessing.cpu_count()\n",
    "num_threads = cpus  * cpu_factor\n",
    "print(f\"######### Running using {num_threads} threads for {cpus} cpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167fcb3b-be4f-4b34-9dce-a81d7cf3d548",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000000 synthetic rows\n",
      "******* Round 1/1000: Loaded 1000000 rows into lgbaeza-apps-customer.telco.cdr\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    executor.map(create_insert_cdr, range(1, num_cycles+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099850a4-f9eb-45ef-a8b7-789657c43c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fe60a60-2aed-4d2f-9a8b-74ee43db667a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Inserted 100.0 M rows in 1.124746568997701 minutes\n"
     ]
    }
   ],
   "source": [
    "print (f\"######### Inserted {(num_cycles*num_rows_batch/1000000):,} M rows in {execution_time/60} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb368876-408b-4480-bbff-409c6947020b",
   "metadata": {},
   "source": [
    "### 2. Run periodically a Cloud Function to copy existent rows in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e808f93-1e18-446f-826a-b9d78219309b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions_framework # Required in Cloud Functions\n",
    "import datetime\n",
    "from google.cloud import bigquery\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "project_id = \"\"\n",
    "dataset_id = f\"\"\n",
    "table_id = \"\"\n",
    "num_cycles = 10\n",
    "rows_to_copy = 10000000 # 10M\n",
    "cpu_factor = 1\n",
    "cpus = multiprocessing.cpu_count()\n",
    "num_threads = cpus  * cpu_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67aa4746-cb1d-4ded-a44e-3929b7162139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copy_rows(i):\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Your BigQuery query\n",
    "    query = f\"\"\"\n",
    "        INSERT INTO `{project_id}.{dataset_id}.{table_id}`\n",
    "        SELECT * FROM `{project_id}.{dataset_id}.{table_id}` LIMIT {rows_to_copy}\n",
    "    \"\"\"\n",
    "    print(query)\n",
    "\n",
    "    # Start the query\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Wait for the query to finish\n",
    "    results = query_job.result()\n",
    "    \n",
    "    print(f\"{query_job.num_dml_affected_rows} rows inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8954df1-8ddd-4099-8856-529261fe55ec",
   "metadata": {},
   "source": [
    "### Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14249b5c-c2e5-46f3-b0c9-939ddf8dd141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        INSERT INTO `lgbaeza-apps-customer.telco.cdr`\n",
      "        SELECT * FROM `lgbaeza-apps-customer.telco.cdr` LIMIT 100\n",
      "    \n",
      "100 rows inserted\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    executor.map(copy_rows, range(1, num_cycles+1)) \n",
    "    \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7989312d-5a0c-4c2a-94ab-750cc8db8268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Copied 100.0M rows in BQ in 0.051648275057474775 minutes\n"
     ]
    }
   ],
   "source": [
    "result = f\"######### Copied {(num_cycles*rows_to_copy/1000000):,}M rows in BQ in {execution_time/60} minutes\"\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bfa316-250a-4cfb-8b2e-dadbfabe7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return result  # Required in Cloud Functons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bebe49-96c3-458d-8226-e115a03ff2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
